{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FSCNN_presentable.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rpLhx0QZ6-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5068ec5f-d249-43a2-81f5-83ededd0c22c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DqGtSZ6Pud_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qezAlmUkhv39"
      },
      "source": [
        "import os, sys, glob, zipfile, functools\n",
        "from sklearn.utils import shuffle\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "mpl.rcParams['figure.figsize'] = (12,12)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.image as mpimg\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "import torch.utils.data as data\n",
        "import utils\n",
        "from metrics import Metric, IoU, ConfusionMatrix\n",
        "from helper import get_filenames, pil_loader, custom_loader, binarize_array, leave_one_out_datasets, batch_transform, imshow_batch, save_checkpoint, load_checkpoint, load_dataset \n",
        "from dataset import Dataset\n",
        "from networks import FastSCNN, _ConvBNReLU, _DSConv, _DWConv, LinearBottleneck, PyramidPooling, LearningToDownsample, GlobalFeatureExtractor, FeatureFusionModule, Classifier, Interpolate\n",
        "from train import Train\n",
        "from test import Test \n",
        "from trainer import train, test, predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH22RsPInOuX"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import transforms as ext_transforms\n",
        "#from metric.iou import IoU\n",
        "save_dir = pathrev + \"\\outputs\"\n",
        "device = torch.cuda.get_device_name\n",
        "height = 224\n",
        "width = 288\n",
        "batch_size = 8\n",
        "epochs = 20\n",
        "\n",
        "learning_rate = 5e-4\n",
        "lr_decay = 0.1\n",
        "lr_decay_epochs = 100\n",
        "weight_decay = 2e-4\n",
        "path = pathrev\n",
        "weighing = 'FSCNN'\n",
        "workers = 4\n",
        "printstep = \"True\"\n",
        "name = 'FastSCNNartery'\n",
        "save_dir = pathrev + \"\\outputs\"\n",
        "imshowbatch = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4sp0vCoTqsh"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "seed = 1\n",
        "img_shape = (224, 288, 3)\n",
        "mask_shape = (224, 288, 1)\n",
        "batch_size = 8\n",
        "im = 224\n",
        "ma = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry8MBDIAlNeR"
      },
      "source": [
        "pathrev = \"/content/drive/My Drive/originals/\"\n",
        "sys.path.append(pathrev)\n",
        "X_full = []\n",
        "y_full = []\n",
        "path = \"/content/drive/My Drive/originals/augmentedartery/\"\n",
        "X_full,y_full =  get_filenames(path)\n",
        "X_full.sort()\n",
        "y_full.sort()\n",
        "X_full , y_full = shuffle(X_full , y_full)\n",
        "X_train,y_train,X_test,y_test,X_val,y_val = leave_one_out_datasets(X_full,y_full)\n",
        "X_train , y_train = shuffle(X_train , y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAgrjxJGW5L9"
      },
      "source": [
        "\n",
        "mode = 'train'\n",
        "batch_size = 8\n",
        "loaders, w_class,class_encoding = load_dataset(Dataset,mode)\n",
        "train_loader, val_loader, test_loader = loaders\n",
        "model = train(train_loader, val_loader, w_class,class_encoding)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGGnxTRrXOWm"
      },
      "source": [
        "mode = 'test'\n",
        "    # Intialize a new model\n",
        "num_classes = 2 #len(class_encoding)\n",
        "model = FastSCNN(num_classes)\n",
        "predtimes = []\n",
        "# Initialize a optimizer just so we can retrieve the model from the\n",
        "# checkpoint\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "loaders, w_class, class_encoding = load_dataset(Dataset,mode)\n",
        "train_loader, val_loader, test_loader = loaders\n",
        "# Load the previoulsy saved model state to the model\n",
        "model = load_checkpoint(model, optimizer, '/content/drive/My Drive/originals/outputs',\n",
        "                          'FastSCNNartery')[0]\n",
        "\n",
        "test(model, test_loader, w_class, class_encoding,predtimes)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}